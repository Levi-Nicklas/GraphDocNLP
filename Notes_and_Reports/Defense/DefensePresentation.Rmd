---
title: "Graph Kernels as Preprocessing for Unsupervised Learning: Two Case Studies"
author: "Levi C. Nicklas (B.S. Applied Mathematics)"
subtitle: "<html><div style='float:left'></div><hr color='#522A87' size=1px width=796px></html>"
#author: Levi Nicklas
date: Masters of Science in Computer Science Candidate #"`r format(Sys.time(), '%d %B %Y')`"
output:
  xaringan::moon_reader:
    css: ["poly.css", metropolis, metropolis-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: false
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
library(here)
knitr::opts_chunk$set(echo = FALSE)
```


# Introduction to the Data

Two data sets are use for all of the analyses, one coming from the National Highway Traffic Safety Administration (NHTSA) and one from the popular social media website [reddit.com](reddit.com/r/mentalhealth/). 

The NHTSA data are a series of special crash investigations (SCI) which are publically available through a portal in PDF format. $(N=48)$

The reddit data are public online forum discussion on the `r\MentalHealth` subreddit which satisfied query criteria. $(N=1000)$
---

# Introduction to the Data (cont.)
## NHTSA SCI Reports

- **Motivation:** These efforts and results support iniatives in Florida Polytechnic University's Advanced Mobility Institute (AMI) which focuses in the development of connected and fully autonomous vehicles. These reports are all on incidents which involved ambulances in the collision. The events all represent "edge cases" that are rare and need to be characterized properly for AMI's future success in developing robust autonomous vehicles.

- **Format and Collection:** the reports are all stored as PDF files which are all converted to XML and from which the text of concern is then parsed out for further processing and analysis.

```{r, out.width = "400px", fig.retina = 3, echo  = FALSE}
# OPEN IN CHROME ONLY
knitr::include_graphics("https://crashviewer.nhtsa.dot.gov/Images/NHTSA_Logo_w_tag.png")
```
---

# Introduction to the Data (cont.)
## Mental Health Subreddit

- **Motivation:** Previously published research work was focused on text mining within reddit subreddits focused on opiate addiction. The paper focused on clustering of posts/comments from the data collected from the subreddit. Using this type of data with new methods builds upon my existing work.

- **Format and Collection:** the thread text is collected with `{redditExtractor}` and then must undergo a cleaning and reformating, as the tabular format is structured such that observational units are threads. 

```{r, out.width = "300px", fig.retina = 3, echo  = FALSE}
# OPEN IN CHROME ONLY
knitr::include_graphics("https://logos-download.com/wp-content/uploads/2016/06/Reddit_logo_full_1.png")
```

---

# Introduction to the Data (cont.)
## Comparison of Text

The datasets were chosen for the analyses completed here, not only because of their importance to university projects and past research, but also becuase the datasets' text content differs a great deal.

.pull-left[
**NHTSA**:

- Lengthy documents.

- Formal language. 

- Small corpus.
]
.pull-right[
**reddit**:

- Short documents.

- Informal language; "netspeak" and slang.

- Large corpus.
]
---

# Introduction to Methods
## Why Graphs?

Graphs are a great model for natural language processing!

- Graph representations of text can be composed using bigrams, n-grams, _skip-grams_, etc.

- Graph representations of text preserve more of the rich structures of language, e.g. phrases, idioms, and figures of speech.

- Avoid relying on assumptions about underlying distribution of words like some bag-of-words models do.

- Graph representations allow for a whole new set of methods to be applied to the data.

---

# Introduction to Methods (cont.)
## Example of Skip-gram Graph
.pull-up[
```{r, out.width = "400px", fig.retina = 3, echo  = FALSE}
# OPEN IN CHROME ONLY
knitr::include_graphics("https://raw.githubusercontent.com/Levi-Nicklas/GraphDocNLP/main/Thesis_Tex/Content/Images/reddit_network.png")
```

_Note:_ skip grams with window width $k=2$.
]
.pull-down[


Notice we have some phrases/ideas represented in the graph:

- "stuttering" [in a] "meeting" [with] "bosses"

- "people" "feel" "approachable"

- "feel" "aura" "exude(s)" "coldness"
]
---

# Introduction to Methods (cont.)
## Why Graph Kernels?

_Graph kernels_ are a family of methods which are used to compute similarity between graphs, which then can be used as a kernel in other applications. The kernel  matrix is then able to be used in methods like support vector machines, or in this case hierarchical clustering.

In this case a specific type of graph kernel is used: the edge histogram kernel. The edge histogram kernel has the advantage of a more efficient computation than other, more complicated, graph kernels. Since the reddit dataset has such a large corpus and the NHTSA dataset has such large documents, it was of particular concern that computation be efficient. 
---

# Introduction to Methods (cont.)
## How is the kernel used?

The graph kernel matrix is a _similarity matix_ and the _hierarchical clustering_ that is used requires a distance matrix. For this a simple function is applied to take the element-wise multiplicative inverse, and we use the resulting matrix as a distance matrix in hierarchical clustering. 

Through the use of hierarchical clustering we obtain dendrograms that allow for clean, visual, interpretation of clustering results. The 