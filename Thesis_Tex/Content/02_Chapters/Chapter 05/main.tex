%%%%%%%%%%%%%%%%%%%%%%%%
%
%   Thesis template by Youssif Al-Nashif
%
%   May 2020
%
%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion}

\hspace*{0.3cm} Though applying several different methods in conjunction with one another (skip-grams, graph kernels, and clustering), unsupervised clustering can be done on text while preserving as much of the rich information from the original text as possible. \\

The NHTSA results, and their clusters, can be used to inform other research initiatives of similar scenarios for ambulance crashes. Identifying these clusters, providing summarized results, like n-gram graphs and term frequency/inverse document frequency lists, allows for information about similar crash reports to be compiled. This compiled information can then be used to generate more ``edge-case" scenarios for Florida Polytechnic University's Autonomous Mobility Institute and their work on autonomous vehicles; rare cases are not always available in the datasets used to train autonomous driving models, and this kind of research could help inform their decision making moving forward.\\

In the reddit dataset analysis, the large samples ($N=1000$) used in the study here were accelerated through use of parallel programming and made this analysis possible. The results of the analysis showed that prominent clusters were formed. The dendrogram in Figure 4.7 displays very encouraging results, being that the clusters not only stood out from one another, but that the clusters showed that they were collecting some threads according to their query word that was used to gather the original posts/threads. \\

In summary, the methods outlined here will continue to develop into more mature technologies that could be applied to a wide range of natural language processing tasks, being that the graph kernel matrix could be used for a variety of machine learning tasks\textemdash not just hierarchical clustering. These methods can be used in semi-supervised and supervised applications as well. This work opens the door to classification and inference using the graph kernel methods to preprocess text as graph representations.  Once these methods are rebuilt into a clean package for use in high performance computing environments, they will see use in industries that process large amounts of text data.\\

Lastly, building upon the published work from 2020, these methods could be used for intelligent navigation of comments and posts on social media. In a previous paper, ``A Framework for Intelligent Navigation Using Latent Dirichlet Allocation on Reddit Posts about Opiates", smart ways to cluster text and how that could be used to filter harmful, or otherwise unwanted, content from a web user were outlined. These same principles could be applied with the methods applied to the reddit threads here. Additionally, the NHTSA analysis will benefit Florida Polytechnic University's AMI, which study autonomous vehicles. The edge cases which are often absent from training datasets, such as ambulance crashes, can be used to better inform their efforts to improve autonomous vehicles. The many ambulance accidents can be clustered so that instead of recreating 50 ambulance incidents, they can select one or two that represents each cluster. \\

These methods are all available, publicly, on a GitHub repository at \texttt{https://github.com/Levi-Nicklas/GraphDocNLP}. Updates may be made and the software written can be used, adapted, recreated, scrutinized, and more by the software development and data science communities that use GitHub. This open sourcing of the software leave the work conducted here open to examination, and will lead to better open science for the community.

\nocite{vishwanathan2010graph}
\nocite{kriege2020survey}
\nocite{nikolentzos2017shortest}
\nocite{kondor2002diffusion}
\nocite{vazirgiannis2018graphrep}
\nocite{cheng2006n}
\nocite{rosenfeld2020kernel}
\nocite{akioyamen2020framework}
\nocite{wickham2019welcome}
\nocite{sugiyama2018graphkernels}
\nocite{sugiyama2015halting}
\nocite{csardi2013package}
\nocite{csardi2006igraph}
\nocite{silge2016tidytext}
\nocite{rivera2015package}
\nocite{wickham2010stringr}
\nocite{bengtsson2020unifying}







